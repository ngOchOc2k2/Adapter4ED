{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, RobertaTokenizer\n",
    "from model.engine import BertClassifier\n",
    "from model.bert import BertModel\n",
    "from model.roberta import RobertaModel\n",
    "from train import DoubleLoss\n",
    "from transformers import AutoModel, BertModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Since, we want to optimize only parameters of the adapter modules and layer normalization\n",
    "# l=[\"adapter\", \"LayerNorm\"]\n",
    "# [n for n, p in model.named_parameters() if any([(nd in n) for nd in l])]\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = BertClassifier(model_path='roberta-base', num_labels=100, tokenizer='roberta-base')\n",
    "model_bert = AutoModel.from_pretrained('roberta-base')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luungoc/.local/lib/python3.11/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from config import *\n",
    "from torch import nn\n",
    "import config\n",
    "import wandb\n",
    "from tqdm import tqdm, trange\n",
    "from model import BertClassifier\n",
    "from transformers import BertTokenizer, AdamW , get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "layers = [\"adapter\", \"LayerNorm\"]\n",
    "params = [p for n, p in model_bert.named_parameters() \\\n",
    "                if any([(nd in n) for nd in layers])]\n",
    "\n",
    "optimizer = AdamW(params, lr=config.LEARNING_RATE)\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer, num_warmup_steps = int(0.1 * len(self.train_dataset))*config.EPOCHS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = [\"adapter\", \"LayerNorm\"]\n",
    "# optimizer_grouped_parameters = [\n",
    "#     {\n",
    "#         \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "#         \"weight_decay\": 0.1,\n",
    "#     },\n",
    "#     {\n",
    "#         \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "#         \"weight_decay\": 0.0,\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "no_decay = [\"adapter.proj_up.bias\", \"adapter.proj_down.bias\", \"LayerNorm\"]\n",
    "cls_bias = ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
    "cls_weight = ['cls.seq_relationship.weight', 'cls.predicions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
    "layers = [\"adapter.proj_up.weight\", \"adapter.proj_down.weight\"]\n",
    "layers.extend(cls_weight)\n",
    "no_decay.extend(cls_bias)\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if any([nd in n for nd in layers])],\n",
    "        \"weight_decay\": 0.1,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2417664"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_params_count = 0\n",
    "for group in optimizer_grouped_parameters:\n",
    "    for param in group[\"params\"]:\n",
    "        trainable_params_count += param.numel()\n",
    "        \n",
    "trainable_params_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = model_bert(tok).last_hidden_state[0, 0, :]  \n",
    "b2 = torch.tensor([0 for _ in range(100)], dtype=torch.float)\n",
    "b2[1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_event_detection(predictions, ground_truth):\n",
    "    predicted_events = set((event[0], frozenset(event[1].items())) for event in predictions)\n",
    "    actual_events = set((event[0], frozenset(event[1].items())) for event in ground_truth)\n",
    "\n",
    "    correct_predictions = len(predicted_events.intersection(actual_events))\n",
    "    total_predicted = len(predicted_events)\n",
    "    total_actual = len(actual_events)\n",
    "\n",
    "    precision = correct_predictions / total_predicted if total_predicted > 0 else 0.0\n",
    "    recall = correct_predictions / total_actual if total_actual > 0 else 0.0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0.0\n",
    "\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# Ví dụ sử dụng hàm đánh giá\n",
    "predicted_events = [(\"attack\", {\"location\": \"city\", \"time\": \"morning\"}),\n",
    "                     (\"meeting\", {\"location\": \"office\", \"time\": \"afternoon\"})]\n",
    "\n",
    "actual_events = [(\"meeting\", {\"location\": \"office\", \"time\": \"afternoon\"}),\n",
    "                 (\"celebration\", {\"location\": \"park\", \"time\": \"evening\"})]\n",
    "\n",
    "# Đánh giá\n",
    "precision, recall, f1_score = evaluate_event_detection(predicted_events, actual_events)\n",
    "\n",
    "# In kết quả\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
